{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 as cv\n",
    "import tf2onnx\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(dataset_dir,BATCH_SIZE,EPOCHS):\n",
    "    IMG_HEIGHT=180\n",
    "    IMG_WIDTH=180\n",
    "    \n",
    "# defining the model\n",
    "    try:\n",
    "        if len(tf.config.list_physical_devices('CPU'))==1:\n",
    "            with tf.device('CPU'):\n",
    "                train_ds= tf.keras.utils.image_dataset_from_directory(dataset_dir,validation_split=0.4,subset='training',seed=34,image_size=(IMG_HEIGHT,IMG_WIDTH),batch_size=BATCH_SIZE)\n",
    "                val_ds=   tf.keras.utils.image_dataset_from_directory(dataset_dir,validation_split=0.4,subset='validation',seed=34,image_size=(IMG_HEIGHT,IMG_WIDTH),batch_size=BATCH_SIZE)\n",
    "                class_names=train_ds.class_names\n",
    "                AUTOTUNE = tf.data.AUTOTUNE\n",
    "                train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "                val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "                my_model = tf.keras.Sequential([tf.keras.layers.Input(shape=(180,180,3)),\n",
    "                          tf.keras.layers.Rescaling(1./255,name=\"Normalising_layer\"),\n",
    "                          tf.keras.layers.Flatten(name=\"Flattening_layer\"),\n",
    "                          tf.keras.layers.Dense(64, activation='relu',name=\"Dense1_layer\"),\n",
    "                          tf.keras.layers.Dense(32, activation= 'relu',name=\"Dense2_layer\"),\n",
    "                          tf.keras.layers.Dense(len(class_names),activation='softmax',name=\"Softmax\")\n",
    "                        ])\n",
    "                with open(\"log.txt\",'a') as f:\n",
    "                    print(my_model.summary())\n",
    "                keras.utils.plot_model(my_model, \"my_first_model.png\",show_shapes=True)\n",
    "                my_model.compile(optimizer='adam',loss=tf.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "                \n",
    "    except Exception as e:\n",
    "        with open(\"log.txt\",'a') as f:\n",
    "            print(\"AN EXCEPTION HAS OCCURED:-\")\n",
    "            print(e)\n",
    "    \n",
    "# training the model\n",
    "    try:\n",
    "        if len(tf.config.list_physical_devices('GPU'))==1:\n",
    "            with tf.device('GPU'):\n",
    "                my_model_hist=my_model.fit(train_ds,validation_data=val_ds,epochs=EPOCHS)\n",
    "        else:\n",
    "            with tf.device('CPU'):\n",
    "                my_model_hist=my_model.fit(train_ds,validation_data=val_ds,epochs=EPOCHS)\n",
    "                \n",
    "    except Exception as e:\n",
    "        with open(\"log.txt\",'a') as f:\n",
    "            print(\"AN EXCEPTION HAS OCCURED:-\")\n",
    "            print(e)\n",
    "                    \n",
    "    return(my_model,my_model_hist,class_names)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orig_stdout = sys.stdout\n",
    "f = open('log.txt', 'a')\n",
    "sys.stdout = f\n",
    "my_model,my_model_hist,classes_names= get_trained_model('/media/atharva_patwe/Data/auto cad/TATA project/DNN GUI CV/cam_cap_dataset',4,30)\n",
    "print(my_model_hist.history)\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/sequential/assets\n"
     ]
    }
   ],
   "source": [
    "path=os.path.join(\"/tmp\",my_model.name)\n",
    "my_model.save(os.path.join(\"/tmp\",my_model.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = (tf.TensorSpec((None, 180,180, 3), tf.float32, name=\"input\"),)\n",
    "output_path = my_model.name + \".onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atharva_patwe/miniconda3/envs/tf/lib/python3.9/site-packages/tf2onnx/tf_loader.py:711: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "model is successfully created\n"
     ]
    }
   ],
   "source": [
    "model_proto, _ = tf2onnx.convert.from_keras(my_model, input_signature=spec, opset=13, output_path=output_path)\n",
    "output_names = [n.name for n in model_proto.graph.output]\n",
    "print(\"model is successfully created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 180, 3)\n",
      "(1, 180, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "img=cv.imread('/media/atharva_patwe/Data/auto cad/TATA project/DNN GUI CV/test_dataset/present/image_no63.jpg')\n",
    "img=cv.resize(img, (180,180))\n",
    "print(img.shape)\n",
    "img=np.expand_dims(img,axis=0).astype(np.float32)\n",
    "print(img.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "present\n",
      "Confidence:- 96.62252068519592 %\n"
     ]
    }
   ],
   "source": [
    "a=my_model.predict(img)\n",
    "prediction=np.argmax(a)\n",
    "print(classes_names[prediction])\n",
    "print(f\"Confidence:- {np.max(a)*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.03377428, 0.9662257 ]], dtype=float32)]\n",
      "['Softmax']\n",
      "Softmax\n",
      "['Softmax']\n",
      "1\n",
      "Predicted Class is :\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as rt\n",
    "\n",
    "providers = ['CPUExecutionProvider']\n",
    "m = rt.InferenceSession(output_path, providers=providers)\n",
    "onnx_pred = m.run(output_names, {\"input\": img})\n",
    "print(onnx_pred)\n",
    "\n",
    "output_classes= m.get_outputs()[0].name\n",
    "print(output_names)\n",
    "print(output_classes)\n",
    "\n",
    "prediction_onnx=np.argmax(onnx_pred)\n",
    "output =[node.name for node in model_proto.graph.output]\n",
    "print(output)\n",
    "print(prediction_onnx)\n",
    "print(\"Predicted Class is :\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd38ec3fb9f73ca4d5b65b9dd34268daf95e0f7b10c764d9398468d2a8513438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
