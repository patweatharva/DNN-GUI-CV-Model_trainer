{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 as cv\n",
    "import tf2onnx\n",
    "import os\n",
    "import sys\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(dataset_dir,BATCH_SIZE,EPOCHS):\n",
    "    IMG_HEIGHT=180\n",
    "    IMG_WIDTH=180\n",
    "    \n",
    "# defining the model\n",
    "    try:\n",
    "        if len(tf.config.list_physical_devices('CPU'))==1:\n",
    "            with tf.device('CPU'):\n",
    "                train_ds= tf.keras.utils.image_dataset_from_directory(dataset_dir,validation_split=0.4,subset='training',seed=34,image_size=(IMG_HEIGHT,IMG_WIDTH),batch_size=BATCH_SIZE)\n",
    "                val_ds=   tf.keras.utils.image_dataset_from_directory(dataset_dir,validation_split=0.4,subset='validation',seed=34,image_size=(IMG_HEIGHT,IMG_WIDTH),batch_size=BATCH_SIZE)\n",
    "                class_names=train_ds.class_names\n",
    "                AUTOTUNE = tf.data.AUTOTUNE\n",
    "                train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "                val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "                my_model = tf.keras.Sequential([tf.keras.layers.Input(shape=(180,180,3)),\n",
    "                          tf.keras.layers.Rescaling(1./255,name=\"Normalising_layer\"),\n",
    "                          tf.keras.layers.Flatten(name=\"Flattening_layer\"),\n",
    "                          tf.keras.layers.Dense(64, activation='relu',name=\"Dense1_layer\"),\n",
    "                          tf.keras.layers.Dense(32, activation= 'relu',name=\"Dense2_layer\"),\n",
    "                          tf.keras.layers.Dense(len(class_names),activation='softmax',name=\"Softmax_layer\")\n",
    "                        ])\n",
    "                with open(\"log.txt\",'a') as f:\n",
    "                    print(my_model.summary())\n",
    "                keras.utils.plot_model(my_model, \"my_first_model.png\",show_shapes=True)\n",
    "                my_model.compile(optimizer='adam',loss=tf.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "                \n",
    "    except Exception as e:\n",
    "        with open(\"log.txt\",'a') as f:\n",
    "            print(\"AN EXCEPTION HAS OCCURED:-\")\n",
    "            print(e)\n",
    "    \n",
    "# training the model\n",
    "    try:\n",
    "        if len(tf.config.list_physical_devices('GPU'))==1:\n",
    "            with tf.device('GPU'):\n",
    "                my_model_hist=my_model.fit(train_ds,validation_data=val_ds,epochs=EPOCHS)\n",
    "        else:\n",
    "            with tf.device('CPU'):\n",
    "                my_model_hist=my_model.fit(train_ds,validation_data=val_ds,epochs=EPOCHS)\n",
    "                \n",
    "    except Exception as e:\n",
    "        with open(\"log.txt\",'a') as f:\n",
    "            print(\"AN EXCEPTION HAS OCCURED:-\")\n",
    "            print(e)\n",
    "                    \n",
    "    return(my_model,my_model_hist)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orig_stdout = sys.stdout\n",
    "f = open('log.txt', 'a')\n",
    "sys.stdout = f\n",
    "my_model,my_model_hist= get_trained_model('/media/atharva_patwe/Data/auto cad/TATA project/DNN GUI CV/gtrtgr',4,30)\n",
    "print(my_model_hist.history)\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=os.path.join(\"/tmp\",my_model.name)\n",
    "my_model.save(os.path.join(\"/tmp\",my_model.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = (tf.TensorSpec((None, 180,180, 3), tf.float32, name=\"input\"),)\n",
    "output_path = my_model.name + \".onnx\"\n",
    "\n",
    "model_proto, _ = tf2onnx.convert.from_keras(my_model, input_signature=spec, opset=13, output_path=output_path)\n",
    "output_names = [n.name for n in model_proto.graph.output]\n",
    "print(\"model is successfully created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img=cv.imread('/media/atharva_patwe/Data/auto cad/TATA project/DNN GUI CV/gtrtgr/ertgwertwergwer/image_no3.jpg')\n",
    "img=cv.resize(img, (180,180))\n",
    "print(img.shape)\n",
    "img=np.expand_dims(img,axis=0)\n",
    "print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['atharva','yashwanth']\n",
    "a=my_model.predict(img)\n",
    "print(a)\n",
    "prediction=np.argmax(a)\n",
    "print(class_names[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "\n",
    "providers = ['CPUExecutionProvider']\n",
    "m = rt.InferenceSession(output_path, providers=providers)\n",
    "onnx_pred = m.run(output_names, {\"input\": img})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd38ec3fb9f73ca4d5b65b9dd34268daf95e0f7b10c764d9398468d2a8513438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
